{"cells":[{"cell_type":"markdown","source":["## Pre-Processing"],"metadata":{"id":"dUVMSBm4y35X"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3V5ufSM9wqje","outputId":"31653543-3a0a-4cf3-bad9-16f8a74c7b0d","executionInfo":{"status":"ok","timestamp":1643217835122,"user_tz":-60,"elapsed":5383,"user":{"displayName":"Mario Bianchi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiYjqJ5A8gRK7lZX57CyeAJHOrmxNdh0QGBaLkAFg=s64","userId":"04504788663289352355"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.15.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.4.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.4.2)\n","Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.47)\n","Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.3)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.10.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.3)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.6)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.7.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n"]}],"source":["!pip install transformers "]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2PDvilZ3Nce_","outputId":"85f4b876-9396-4844-8ca5-5910b3ea2b52","executionInfo":{"status":"ok","timestamp":1643217835563,"user_tz":-60,"elapsed":444,"user":{"displayName":"Mario Bianchi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiYjqJ5A8gRK7lZX57CyeAJHOrmxNdh0QGBaLkAFg=s64","userId":"04504788663289352355"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Wed Jan 26 17:23:54 2022       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 495.46       Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   72C    P8    32W / 149W |      0MiB / 11441MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}],"source":["!nvidia-smi"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gTsFJKO_pbjv"},"outputs":[],"source":["import pandas as pd\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.model_selection import train_test_split\n","from transformers import BertTokenizer, BertForSequenceClassification, AdamW, BertConfig, get_linear_schedule_with_warmup\n","import matplotlib as plt\n","import torch\n","from torch.utils.data import DataLoader, RandomSampler, SequentialSampler, TensorDataset\n","from sklearn.metrics import *\n","import numpy as np\n","import pandas as pd\n","from sklearn.metrics import matthews_corrcoef\n","from distutils.version import LooseVersion as LV"]},{"cell_type":"code","source":["if torch.cuda.is_available():\n","    device = torch.device('cuda')\n","    devicename = '['+torch.cuda.get_device_name(0)+']'\n","else:\n","    device = torch.device('cpu')\n","    devicename = \"\"\n","    \n","print('Using PyTorch version:', torch.__version__,\n","      'Device:', device, devicename)\n","assert(LV(torch.__version__) >= LV(\"1.0.0\"))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KLAF964_Q5oI","executionInfo":{"status":"ok","timestamp":1643217840184,"user_tz":-60,"elapsed":360,"user":{"displayName":"Mario Bianchi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiYjqJ5A8gRK7lZX57CyeAJHOrmxNdh0QGBaLkAFg=s64","userId":"04504788663289352355"}},"outputId":"4e154b0d-e134-433b-c834-66b89a21b414"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Using PyTorch version: 1.10.0+cu111 Device: cuda [Tesla K80]\n"]}]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')\n","\n","filename1 = 'drive/MyDrive/TextAnalytics/training_set_1.csv'\n","filename2 = 'drive/MyDrive/TextAnalytics/training_set_2.csv'\n","filename3 = 'drive/MyDrive/TextAnalytics/test_set.csv'"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hCxR_JWBQU6V","executionInfo":{"status":"ok","timestamp":1643217842156,"user_tz":-60,"elapsed":1978,"user":{"displayName":"Mario Bianchi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiYjqJ5A8gRK7lZX57CyeAJHOrmxNdh0QGBaLkAFg=s64","userId":"04504788663289352355"}},"outputId":"d1ccbd71-c95d-4f8f-a65c-c415fb606dfe"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["df_train1 = pd.read_csv(filename1)\n","df_train2 = pd.read_csv(filename2)\n","df_test = pd.read_csv(filename3)\n","\n","df_train1.head(2)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":366},"id":"JkA-HwExRCjK","executionInfo":{"status":"ok","timestamp":1643217844431,"user_tz":-60,"elapsed":2277,"user":{"displayName":"Mario Bianchi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiYjqJ5A8gRK7lZX57CyeAJHOrmxNdh0QGBaLkAFg=s64","userId":"04504788663289352355"}},"outputId":"e08afccc-e648-4a6f-ad54-4e97512584de"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["\n","  <div id=\"df-036b1b5e-d100-440c-883d-2c04ea90aa64\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Unnamed: 0</th>\n","      <th>review_rating</th>\n","      <th>date</th>\n","      <th>year</th>\n","      <th>review_title</th>\n","      <th>body</th>\n","      <th>product_title</th>\n","      <th>product_rating</th>\n","      <th>language</th>\n","      <th>english</th>\n","      <th>pos_review</th>\n","      <th>body_tok</th>\n","      <th>body_tok_ngrams</th>\n","      <th>body_lem_ngrams</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>27931</td>\n","      <td>2</td>\n","      <td>September 13, 2018</td>\n","      <td>2018</td>\n","      <td>Bad battery</td>\n","      <td>Iâ€™m happy with the way the phone looks but upo...</td>\n","      <td>Apple iPhone 6S, 64GB, Rose Gold - For AT&amp;T / ...</td>\n","      <td>3.6</td>\n","      <td>en</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>['happy', 'way', 'phone', 'looks', 'upon', 'op...</td>\n","      <td>['happy', 'way', 'phone', 'looks', 'upon', 'op...</td>\n","      <td>['LEM_happy', 'LEM_way', 'LEM_phone', 'LEM_loo...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>18619</td>\n","      <td>1</td>\n","      <td>June 18, 2018</td>\n","      <td>2018</td>\n","      <td>Very bad experience and Amazon didn't help me ...</td>\n","      <td>the brand itself is not a problem. the problem...</td>\n","      <td>Samsung Galaxy S7 SM-G930A AT&amp;T Unlocked Smart...</td>\n","      <td>3.1</td>\n","      <td>en</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>['brand', 'problem', 'problem', 'seller', 'pho...</td>\n","      <td>['brand', 'problem', 'problem', 'seller', 'pho...</td>\n","      <td>['LEM_brand', 'LEM_problem', 'LEM_problem', 'L...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-036b1b5e-d100-440c-883d-2c04ea90aa64')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-036b1b5e-d100-440c-883d-2c04ea90aa64 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-036b1b5e-d100-440c-883d-2c04ea90aa64');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["   Unnamed: 0  ...                                    body_lem_ngrams\n","0       27931  ...  ['LEM_happy', 'LEM_way', 'LEM_phone', 'LEM_loo...\n","1       18619  ...  ['LEM_brand', 'LEM_problem', 'LEM_problem', 'L...\n","\n","[2 rows x 14 columns]"]},"metadata":{},"execution_count":6}]},{"cell_type":"code","source":["# Usiamo il TRAINING SET 1\n","\n","train = df_train1[['body_tok', 'pos_review']]\n","\n","test = df_test[['body_tok', 'pos_review']]\n","\n","train.head(2)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":112},"id":"cohdfCNaRUgu","executionInfo":{"status":"ok","timestamp":1643217844432,"user_tz":-60,"elapsed":10,"user":{"displayName":"Mario Bianchi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiYjqJ5A8gRK7lZX57CyeAJHOrmxNdh0QGBaLkAFg=s64","userId":"04504788663289352355"}},"outputId":"5d7df102-bacd-47df-84d6-d0b109bef8c3"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["\n","  <div id=\"df-c113497f-c437-4d37-80e0-ef8d8be49ea8\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>body_tok</th>\n","      <th>pos_review</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>['happy', 'way', 'phone', 'looks', 'upon', 'op...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>['brand', 'problem', 'problem', 'seller', 'pho...</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c113497f-c437-4d37-80e0-ef8d8be49ea8')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-c113497f-c437-4d37-80e0-ef8d8be49ea8 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-c113497f-c437-4d37-80e0-ef8d8be49ea8');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["                                            body_tok  pos_review\n","0  ['happy', 'way', 'phone', 'looks', 'upon', 'op...           0\n","1  ['brand', 'problem', 'problem', 'seller', 'pho...           0"]},"metadata":{},"execution_count":7}]},{"cell_type":"code","source":["# Preparazione due training set\n","X_train = train['body_tok']\n","\n","y_train = train['pos_review']\n","\n","\n","# Preparazione test set\n","X_test = test['body_tok']\n","y_test = test['pos_review']\n","\n","len(X_train),len(y_train),len(X_test),len(y_test)"],"metadata":{"id":"4ECS7OT5Racu","executionInfo":{"status":"ok","timestamp":1643217844432,"user_tz":-60,"elapsed":8,"user":{"displayName":"Mario Bianchi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiYjqJ5A8gRK7lZX57CyeAJHOrmxNdh0QGBaLkAFg=s64","userId":"04504788663289352355"}},"outputId":"ab03462c-92ca-4b8e-adc4-ddb45e1f1a6b","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(10000, 10000, 20000, 20000)"]},"metadata":{},"execution_count":8}]},{"cell_type":"code","source":["# Per Evaluation\n","\n","def model_evaluation(real_v, pred_v):\n","    print(f\"Accuracy sore: {accuracy_score(real_v, pred_v)}\")\n","    print(\"Classification report:\")\n","    print(classification_report(real_v, pred_v))\n","    cm = confusion_matrix(real_v, pred_v)\n","    print (f\"Confusion matrix \\n {cm}\")"],"metadata":{"id":"R-lQt1F0Rcyd"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LI_5jfU26GHF"},"outputs":[],"source":["# Transform target in tensors\n","train_labels = torch.tensor(y_train)\n","\n","test_labels = torch.tensor(y_test)"]},{"cell_type":"markdown","metadata":{"id":"nekumwkAsrwu"},"source":["## BERT Tokenizer\n","    #   (1) Tokenize the sentence.\n","    #   (2) Prepend the `[CLS]` token to the start. \n","    #   (3) Append the `[SEP]` token to the end.\n","    #   (4) Map tokens to their IDs.\n","    #   (5) Pad or truncate the sentence to `max_length`\n","    #   (6) Create attention masks for [PAD] tokens.\n","Function *tokenizer.encode_plus* was used which encapsulates the whole procedure"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"k-yNyONVw9_B"},"outputs":[],"source":["# Load the BERT tokenizer.\n","tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"j9tXJWkjxPGH","executionInfo":{"status":"ok","timestamp":1643217846456,"user_tz":-60,"elapsed":13,"user":{"displayName":"Mario Bianchi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiYjqJ5A8gRK7lZX57CyeAJHOrmxNdh0QGBaLkAFg=s64","userId":"04504788663289352355"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"1ae944c4-fa1b-45a8-9640-6422ceb74cfe"},"outputs":[{"output_type":"stream","name":"stdout","text":["Tokenized review:  ['[', \"'\", 'happy', \"'\", ',', \"'\", 'way', \"'\", ',', \"'\", 'phone', \"'\", ',', \"'\", 'looks', \"'\", ',', \"'\", 'upon', \"'\", ',', \"'\", 'opening', \"'\", ',', \"'\", 'shows', \"'\", ',', \"'\", '88', \"'\", ',', \"'\", 'battery', \"'\", ',', \"'\", 'lifespan', \"'\", ',', \"'\", 'order', \"'\", ',', \"'\", 'certified', \"'\", ',', \"'\", 'ref', '##ur', '##b', \"'\", ',', \"'\", 'really', \"'\", ',', \"'\", 'replacing', \"'\", ',', \"'\", 'new', \"'\", ',', \"'\", 'battery', \"'\", ',', \"'\", 'price', \"'\", ',', \"'\", 'expensive', \"'\", ',', \"'\", 'enough', \"'\", ',', \"'\", 'phone', \"'\", ',', \"'\", 'work', \"'\", ',', \"'\", 'new', \"'\", ',', \"'\", 'includes', \"'\", ',', \"'\", 'battery', \"'\", ',', \"'\", 'hold', \"'\", ',', \"'\", 'complete', \"'\", ',', \"'\", 'charge', \"'\", ',', \"'\", 'pleased', \"'\", ',', '[', \"'\", 'b', '_', 'happy', '_', 'way', \"'\", ',', \"'\", 'b', '_', 'way', '_', 'phone', \"'\", ',', \"'\", 'b', '_', 'phone', '_', 'looks', \"'\", ',', \"'\", 'b', '_', 'looks', '_', 'upon', \"'\", ',', \"'\", 'b', '_', 'upon', '_', 'opening', \"'\", ',', \"'\", 'b', '_', 'opening', '_', 'shows', \"'\", ',', \"'\", 'b', '_', 'shows', '_', '88', \"'\", ',', \"'\", 'b', '_', '88', '_', 'battery', \"'\", ',', \"'\", 'b', '_', 'battery', '_', 'lifespan', \"'\", ',', \"'\", 'b', '_', 'lifespan', '_', 'order', \"'\", ',', \"'\", 'b', '_', 'order', '_', 'certified', \"'\", ',', \"'\", 'b', '_', 'certified', '_', 'ref', '##ur', '##b', \"'\", ',', \"'\", 'b', '_', 'ref', '##ur', '##b', '_', 'really', \"'\", ',', \"'\", 'b', '_', 'really', '_', 'replacing', \"'\", ',', \"'\", 'b', '_', 'replacing', '_', 'new', \"'\", ',', \"'\", 'b', '_', 'new', '_', 'battery', \"'\", ',', \"'\", 'b', '_', 'battery', '_', 'price', \"'\", ',', \"'\", 'b', '_', 'price', '_', 'expensive', \"'\", ',', \"'\", 'b', '_', 'expensive', '_', 'enough', \"'\", ',', \"'\", 'b', '_', 'enough', '_', 'phone', \"'\", ',', \"'\", 'b', '_', 'phone', '_', 'work', \"'\", ',', \"'\", 'b', '_', 'work', '_', 'new', \"'\", ',', \"'\", 'b', '_', 'new', '_', 'includes', \"'\", ',', \"'\", 'b', '_', 'includes', '_', 'battery', \"'\", ',', \"'\", 'b', '_', 'battery', '_', 'hold', \"'\", ',', \"'\", 'b', '_', 'hold', '_', 'complete', \"'\", ',', \"'\", 'b', '_', 'complete', '_', 'charge', \"'\", ',', \"'\", 'b', '_', 'charge', '_', 'pleased', \"'\", ',', \"'\", 't', '_', 'happy', '_', 'way', '_', 'phone', \"'\", ',', \"'\", 't', '_', 'way', '_', 'phone', '_', 'looks', \"'\", ',', \"'\", 't', '_', 'phone', '_', 'looks', '_', 'upon', \"'\", ',', \"'\", 't', '_', 'looks', '_', 'upon', '_', 'opening', \"'\", ',', \"'\", 't', '_', 'upon', '_', 'opening', '_', 'shows', \"'\", ',', \"'\", 't', '_', 'opening', '_', 'shows', '_', '88', \"'\", ',', \"'\", 't', '_', 'shows', '_', '88', '_', 'battery', \"'\", ',', \"'\", 't', '_', '88', '_', 'battery', '_', 'lifespan', \"'\", ',', \"'\", 't', '_', 'battery', '_', 'lifespan', '_', 'order', \"'\", ',', \"'\", 't', '_', 'lifespan', '_', 'order', '_', 'certified', \"'\", ',', \"'\", 't', '_', 'order', '_', 'certified', '_', 'ref', '##ur', '##b', \"'\", ',', \"'\", 't', '_', 'certified', '_', 'ref', '##ur', '##b', '_', 'really', \"'\", ',', \"'\", 't', '_', 'ref', '##ur', '##b', '_', 'really', '_', 'replacing', \"'\", ',', \"'\", 't', '_', 'really', '_', 'replacing', '_', 'new', \"'\", ',', \"'\", 't', '_', 'replacing', '_', 'new', '_', 'battery', \"'\", ',', \"'\", 't', '_', 'new', '_', 'battery', '_', 'price', \"'\", ',', \"'\", 't', '_', 'battery', '_', 'price', '_', 'expensive', \"'\", ',', \"'\", 't', '_', 'price', '_', 'expensive', '_', 'enough', \"'\", ',', \"'\", 't', '_', 'expensive', '_', 'enough', '_', 'phone', \"'\", ',', \"'\", 't', '_', 'enough', '_', 'phone', '_', 'work', \"'\", ',', \"'\", 't', '_', 'phone', '_', 'work', '_', 'new', \"'\", ',', \"'\", 't', '_', 'work', '_', 'new', '_', 'includes', \"'\", ',', \"'\", 't', '_', 'new', '_', 'includes', '_', 'battery', \"'\", ',', \"'\", 't', '_', 'includes', '_', 'battery', '_', 'hold', \"'\", ',', \"'\", 't', '_', 'battery', '_', 'hold', '_', 'complete', \"'\", ',', \"'\", 't', '_', 'hold', '_', 'complete', '_', 'charge', \"'\", ',', \"'\", 't', '_', 'complete', '_', 'charge', '_', 'pleased', \"'\", ']', ']']\n","Original review:  ['happy', 'way', 'phone', 'looks', 'upon', 'opening', 'shows', '88', 'battery', 'lifespan', 'order', 'certified', 'refurb', 'really', 'replacing', 'new', 'battery', 'price', 'expensive', 'enough', 'phone', 'work', 'new', 'includes', 'battery', 'hold', 'complete', 'charge', 'pleased', ['B_happy_way', 'B_way_phone', 'B_phone_looks', 'B_looks_upon', 'B_upon_opening', 'B_opening_shows', 'B_shows_88', 'B_88_battery', 'B_battery_lifespan', 'B_lifespan_order', 'B_order_certified', 'B_certified_refurb', 'B_refurb_really', 'B_really_replacing', 'B_replacing_new', 'B_new_battery', 'B_battery_price', 'B_price_expensive', 'B_expensive_enough', 'B_enough_phone', 'B_phone_work', 'B_work_new', 'B_new_includes', 'B_includes_battery', 'B_battery_hold', 'B_hold_complete', 'B_complete_charge', 'B_charge_pleased', 'T_happy_way_phone', 'T_way_phone_looks', 'T_phone_looks_upon', 'T_looks_upon_opening', 'T_upon_opening_shows', 'T_opening_shows_88', 'T_shows_88_battery', 'T_88_battery_lifespan', 'T_battery_lifespan_order', 'T_lifespan_order_certified', 'T_order_certified_refurb', 'T_certified_refurb_really', 'T_refurb_really_replacing', 'T_really_replacing_new', 'T_replacing_new_battery', 'T_new_battery_price', 'T_battery_price_expensive', 'T_price_expensive_enough', 'T_expensive_enough_phone', 'T_enough_phone_work', 'T_phone_work_new', 'T_work_new_includes', 'T_new_includes_battery', 'T_includes_battery_hold', 'T_battery_hold_complete', 'T_hold_complete_charge', 'T_complete_charge_pleased']]\n"]}],"source":["# Example \n","print(\"Tokenized review: \", tokenizer.tokenize(X_train.values[0]))\n","print(\"Original review: \", X_train.values[0])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jIMMjb6Xpi-L","executionInfo":{"status":"ok","timestamp":1643217846456,"user_tz":-60,"elapsed":10,"user":{"displayName":"Mario Bianchi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiYjqJ5A8gRK7lZX57CyeAJHOrmxNdh0QGBaLkAFg=s64","userId":"04504788663289352355"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"22e7f7a6-ab5f-4aaa-f833-e352055a8d43"},"outputs":[{"output_type":"stream","name":"stdout","text":["Token IDs:  [1031, 1005, 3407, 1005, 1010, 1005, 2126, 1005, 1010, 1005, 3042, 1005, 1010, 1005, 3504, 1005, 1010, 1005, 2588, 1005, 1010, 1005, 3098, 1005, 1010, 1005, 3065, 1005, 1010, 1005, 6070, 1005, 1010, 1005, 6046, 1005, 1010, 1005, 26462, 1005, 1010, 1005, 2344, 1005, 1010, 1005, 7378, 1005, 1010, 1005, 25416, 3126, 2497, 1005, 1010, 1005, 2428, 1005, 1010, 1005, 6419, 1005, 1010, 1005, 2047, 1005, 1010, 1005, 6046, 1005, 1010, 1005, 3976, 1005, 1010, 1005, 6450, 1005, 1010, 1005, 2438, 1005, 1010, 1005, 3042, 1005, 1010, 1005, 2147, 1005, 1010, 1005, 2047, 1005, 1010, 1005, 2950, 1005, 1010, 1005, 6046, 1005, 1010, 1005, 2907, 1005, 1010, 1005, 3143, 1005, 1010, 1005, 3715, 1005, 1010, 1005, 7537, 1005, 1010, 1031, 1005, 1038, 1035, 3407, 1035, 2126, 1005, 1010, 1005, 1038, 1035, 2126, 1035, 3042, 1005, 1010, 1005, 1038, 1035, 3042, 1035, 3504, 1005, 1010, 1005, 1038, 1035, 3504, 1035, 2588, 1005, 1010, 1005, 1038, 1035, 2588, 1035, 3098, 1005, 1010, 1005, 1038, 1035, 3098, 1035, 3065, 1005, 1010, 1005, 1038, 1035, 3065, 1035, 6070, 1005, 1010, 1005, 1038, 1035, 6070, 1035, 6046, 1005, 1010, 1005, 1038, 1035, 6046, 1035, 26462, 1005, 1010, 1005, 1038, 1035, 26462, 1035, 2344, 1005, 1010, 1005, 1038, 1035, 2344, 1035, 7378, 1005, 1010, 1005, 1038, 1035, 7378, 1035, 25416, 3126, 2497, 1005, 1010, 1005, 1038, 1035, 25416, 3126, 2497, 1035, 2428, 1005, 1010, 1005, 1038, 1035, 2428, 1035, 6419, 1005, 1010, 1005, 1038, 1035, 6419, 1035, 2047, 1005, 1010, 1005, 1038, 1035, 2047, 1035, 6046, 1005, 1010, 1005, 1038, 1035, 6046, 1035, 3976, 1005, 1010, 1005, 1038, 1035, 3976, 1035, 6450, 1005, 1010, 1005, 1038, 1035, 6450, 1035, 2438, 1005, 1010, 1005, 1038, 1035, 2438, 1035, 3042, 1005, 1010, 1005, 1038, 1035, 3042, 1035, 2147, 1005, 1010, 1005, 1038, 1035, 2147, 1035, 2047, 1005, 1010, 1005, 1038, 1035, 2047, 1035, 2950, 1005, 1010, 1005, 1038, 1035, 2950, 1035, 6046, 1005, 1010, 1005, 1038, 1035, 6046, 1035, 2907, 1005, 1010, 1005, 1038, 1035, 2907, 1035, 3143, 1005, 1010, 1005, 1038, 1035, 3143, 1035, 3715, 1005, 1010, 1005, 1038, 1035, 3715, 1035, 7537, 1005, 1010, 1005, 1056, 1035, 3407, 1035, 2126, 1035, 3042, 1005, 1010, 1005, 1056, 1035, 2126, 1035, 3042, 1035, 3504, 1005, 1010, 1005, 1056, 1035, 3042, 1035, 3504, 1035, 2588, 1005, 1010, 1005, 1056, 1035, 3504, 1035, 2588, 1035, 3098, 1005, 1010, 1005, 1056, 1035, 2588, 1035, 3098, 1035, 3065, 1005, 1010, 1005, 1056, 1035, 3098, 1035, 3065, 1035, 6070, 1005, 1010, 1005, 1056, 1035, 3065, 1035, 6070, 1035, 6046, 1005, 1010, 1005, 1056, 1035, 6070, 1035, 6046, 1035, 26462, 1005, 1010, 1005, 1056, 1035, 6046, 1035, 26462, 1035, 2344, 1005, 1010, 1005, 1056, 1035, 26462, 1035, 2344, 1035, 7378, 1005, 1010, 1005, 1056, 1035, 2344, 1035, 7378, 1035, 25416, 3126, 2497, 1005, 1010, 1005, 1056, 1035, 7378, 1035, 25416, 3126, 2497, 1035, 2428, 1005, 1010, 1005, 1056, 1035, 25416, 3126, 2497, 1035, 2428, 1035, 6419, 1005, 1010, 1005, 1056, 1035, 2428, 1035, 6419, 1035, 2047, 1005, 1010, 1005, 1056, 1035, 6419, 1035, 2047, 1035, 6046, 1005, 1010, 1005, 1056, 1035, 2047, 1035, 6046, 1035, 3976, 1005, 1010, 1005, 1056, 1035, 6046, 1035, 3976, 1035, 6450, 1005, 1010, 1005, 1056, 1035, 3976, 1035, 6450, 1035, 2438, 1005, 1010, 1005, 1056, 1035, 6450, 1035, 2438, 1035, 3042, 1005, 1010, 1005, 1056, 1035, 2438, 1035, 3042, 1035, 2147, 1005, 1010, 1005, 1056, 1035, 3042, 1035, 2147, 1035, 2047, 1005, 1010, 1005, 1056, 1035, 2147, 1035, 2047, 1035, 2950, 1005, 1010, 1005, 1056, 1035, 2047, 1035, 2950, 1035, 6046, 1005, 1010, 1005, 1056, 1035, 2950, 1035, 6046, 1035, 2907, 1005, 1010, 1005, 1056, 1035, 6046, 1035, 2907, 1035, 3143, 1005, 1010, 1005, 1056, 1035, 2907, 1035, 3143, 1035, 3715, 1005, 1010, 1005, 1056, 1035, 3143, 1035, 3715, 1035, 7537, 1005, 1033, 1033]\n"]}],"source":["# Print the sentence mapped to token ids.\n","print('Token IDs: ', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(X_train.values[0])))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"710WdazRpjAk","executionInfo":{"status":"ok","timestamp":1643217846456,"user_tz":-60,"elapsed":6,"user":{"displayName":"Mario Bianchi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiYjqJ5A8gRK7lZX57CyeAJHOrmxNdh0QGBaLkAFg=s64","userId":"04504788663289352355"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"4a1db171-fa4e-4da3-88d8-689467860a99"},"outputs":[{"output_type":"stream","name":"stdout","text":["Tokenized review:  ['[CLS]', '[', \"'\", 'happy', \"'\", ',', \"'\", 'way', \"'\", ',', \"'\", 'phone', \"'\", ',', \"'\", 'looks', \"'\", ',', \"'\", 'upon', \"'\", ',', \"'\", 'opening', \"'\", ',', \"'\", 'shows', \"'\", ',', \"'\", '88', \"'\", ',', \"'\", 'battery', \"'\", ',', \"'\", 'lifespan', \"'\", ',', \"'\", 'order', \"'\", ',', \"'\", 'certified', \"'\", ',', \"'\", 'ref', '##ur', '##b', \"'\", ',', \"'\", 'really', \"'\", ',', \"'\", 'replacing', \"'\", ',', \"'\", 'new', \"'\", ',', \"'\", 'battery', \"'\", ',', \"'\", 'price', \"'\", ',', \"'\", 'expensive', \"'\", ',', \"'\", 'enough', \"'\", ',', \"'\", 'phone', \"'\", ',', \"'\", 'work', \"'\", ',', \"'\", 'new', \"'\", ',', \"'\", 'includes', \"'\", ',', \"'\", 'battery', \"'\", ',', \"'\", 'hold', \"'\", ',', \"'\", 'complete', \"'\", ',', \"'\", 'charge', \"'\", ',', \"'\", 'pleased', \"'\", ',', '[', \"'\", 'b', '_', 'happy', '_', 'way', \"'\", ',', \"'\", 'b', '_', 'way', '_', 'phone', \"'\", ',', \"'\", 'b', '_', 'phone', '_', 'looks', \"'\", ',', \"'\", 'b', '_', 'looks', '_', 'upon', \"'\", ',', \"'\", 'b', '_', 'upon', '_', 'opening', \"'\", ',', \"'\", 'b', '_', 'opening', '_', 'shows', \"'\", ',', \"'\", 'b', '_', 'shows', '_', '88', \"'\", ',', \"'\", 'b', '_', '88', '_', 'battery', \"'\", ',', \"'\", 'b', '_', 'battery', '_', 'lifespan', \"'\", ',', \"'\", 'b', '_', 'lifespan', '_', 'order', \"'\", ',', \"'\", 'b', '_', 'order', '_', 'certified', \"'\", ',', \"'\", 'b', '_', 'certified', '_', 'ref', '##ur', '##b', \"'\", ',', \"'\", 'b', '_', 'ref', '##ur', '##b', '_', 'really', \"'\", ',', \"'\", 'b', '_', 'really', '_', 'replacing', \"'\", ',', \"'\", 'b', '_', 'replacing', '_', 'new', \"'\", ',', \"'\", 'b', '_', 'new', '_', 'battery', \"'\", ',', \"'\", 'b', '_', 'battery', '_', 'price', \"'\", ',', \"'\", 'b', '_', 'price', '_', 'expensive', \"'\", ',', \"'\", 'b', '_', 'expensive', '_', 'enough', \"'\", ',', \"'\", 'b', '_', 'enough', '_', 'phone', \"'\", ',', \"'\", 'b', '_', 'phone', '_', 'work', \"'\", ',', \"'\", 'b', '_', 'work', '_', 'new', \"'\", ',', \"'\", 'b', '_', 'new', '_', 'includes', \"'\", ',', \"'\", 'b', '_', 'includes', '_', 'battery', \"'\", ',', \"'\", 'b', '_', 'battery', '_', 'hold', \"'\", ',', \"'\", 'b', '_', 'hold', '_', 'complete', \"'\", ',', \"'\", 'b', '_', 'complete', '_', 'charge', \"'\", ',', \"'\", 'b', '_', 'charge', '_', 'pleased', \"'\", ',', \"'\", 't', '_', 'happy', '_', 'way', '_', 'phone', \"'\", ',', \"'\", 't', '_', 'way', '_', 'phone', '_', 'looks', \"'\", ',', \"'\", 't', '_', 'phone', '_', 'looks', '_', 'upon', \"'\", ',', \"'\", 't', '_', 'looks', '_', 'upon', '_', 'opening', \"'\", ',', \"'\", 't', '_', 'upon', '_', 'opening', '_', 'shows', \"'\", ',', \"'\", 't', '_', 'opening', '_', 'shows', '_', '88', \"'\", ',', \"'\", 't', '_', 'shows', '_', '88', '_', 'battery', \"'\", ',', \"'\", 't', '_', '88', '_', 'battery', '_', 'lifespan', \"'\", ',', \"'\", 't', '_', 'battery', '_', 'lifespan', '_', 'order', \"'\", ',', \"'\", 't', '_', 'lifespan', '_', 'order', '_', 'certified', \"'\", ',', \"'\", 't', '_', 'order', '_', 'certified', '_', 'ref', '##ur', '##b', \"'\", ',', \"'\", 't', '_', 'certified', '_', 'ref', '##ur', '##b', '_', 'really', \"'\", ',', \"'\", 't', '_', 'ref', '##ur', '##b', '_', 'really', '_', 'replacing', \"'\", ',', \"'\", 't', '_', 'really', '_', 'replacing', '_', 'new', \"'\", ',', \"'\", 't', '_', 'replacing', '_', 'new', '_', 'battery', \"'\", ',', \"'\", 't', '_', 'new', '_', 'battery', '_', 'price', \"'\", ',', \"'\", 't', '_', 'battery', '_', 'price', '_', 'expensive', \"'\", ',', \"'\", 't', '_', 'price', '_', 'expensive', '_', 'enough', \"'\", ',', \"'\", 't', '_', 'expensive', '_', 'enough', '_', 'phone', \"'\", ',', \"'\", 't', '_', 'enough', '_', 'phone', '_', 'work', \"'\", ',', \"'\", 't', '_', 'phone', '_', 'work', '_', 'new', \"'\", ',', \"'\", 't', '_', 'work', '_', 'new', '_', 'includes', \"'\", ',', \"'\", 't', '_', 'new', '_', 'includes', '_', 'battery', \"'\", ',', \"'\", 't', '_', 'includes', '_', 'battery', '_', 'hold', \"'\", ',', \"'\", 't', '_', 'battery', '_', 'hold', '_', 'complete', \"'\", ',', \"'\", 't', '_', 'hold', '_', 'complete', '_', 'charge', \"'\", ',', \"'\", 't', '_', 'complete', '_', 'charge', '_', 'pleased', \"'\", ']', ']', '[SEP]']\n","Token IDs:  [101, 1031, 1005, 3407, 1005, 1010, 1005, 2126, 1005, 1010, 1005, 3042, 1005, 1010, 1005, 3504, 1005, 1010, 1005, 2588, 1005, 1010, 1005, 3098, 1005, 1010, 1005, 3065, 1005, 1010, 1005, 6070, 1005, 1010, 1005, 6046, 1005, 1010, 1005, 26462, 1005, 1010, 1005, 2344, 1005, 1010, 1005, 7378, 1005, 1010, 1005, 25416, 3126, 2497, 1005, 1010, 1005, 2428, 1005, 1010, 1005, 6419, 1005, 1010, 1005, 2047, 1005, 1010, 1005, 6046, 1005, 1010, 1005, 3976, 1005, 1010, 1005, 6450, 1005, 1010, 1005, 2438, 1005, 1010, 1005, 3042, 1005, 1010, 1005, 2147, 1005, 1010, 1005, 2047, 1005, 1010, 1005, 2950, 1005, 1010, 1005, 6046, 1005, 1010, 1005, 2907, 1005, 1010, 1005, 3143, 1005, 1010, 1005, 3715, 1005, 1010, 1005, 7537, 1005, 1010, 1031, 1005, 1038, 1035, 3407, 1035, 2126, 1005, 1010, 1005, 1038, 1035, 2126, 1035, 3042, 1005, 1010, 1005, 1038, 1035, 3042, 1035, 3504, 1005, 1010, 1005, 1038, 1035, 3504, 1035, 2588, 1005, 1010, 1005, 1038, 1035, 2588, 1035, 3098, 1005, 1010, 1005, 1038, 1035, 3098, 1035, 3065, 1005, 1010, 1005, 1038, 1035, 3065, 1035, 6070, 1005, 1010, 1005, 1038, 1035, 6070, 1035, 6046, 1005, 1010, 1005, 1038, 1035, 6046, 1035, 26462, 1005, 1010, 1005, 1038, 1035, 26462, 1035, 2344, 1005, 1010, 1005, 1038, 1035, 2344, 1035, 7378, 1005, 1010, 1005, 1038, 1035, 7378, 1035, 25416, 3126, 2497, 1005, 1010, 1005, 1038, 1035, 25416, 3126, 2497, 1035, 2428, 1005, 1010, 1005, 1038, 1035, 2428, 1035, 6419, 1005, 1010, 1005, 1038, 1035, 6419, 1035, 2047, 1005, 1010, 1005, 1038, 1035, 2047, 1035, 6046, 1005, 1010, 1005, 1038, 1035, 6046, 1035, 3976, 1005, 1010, 1005, 1038, 1035, 3976, 1035, 6450, 1005, 1010, 1005, 1038, 1035, 6450, 1035, 2438, 1005, 1010, 1005, 1038, 1035, 2438, 1035, 3042, 1005, 1010, 1005, 1038, 1035, 3042, 1035, 2147, 1005, 1010, 1005, 1038, 1035, 2147, 1035, 2047, 1005, 1010, 1005, 1038, 1035, 2047, 1035, 2950, 1005, 1010, 1005, 1038, 1035, 2950, 1035, 6046, 1005, 1010, 1005, 1038, 1035, 6046, 1035, 2907, 1005, 1010, 1005, 1038, 1035, 2907, 1035, 3143, 1005, 1010, 1005, 1038, 1035, 3143, 1035, 3715, 1005, 1010, 1005, 1038, 1035, 3715, 1035, 7537, 1005, 1010, 1005, 1056, 1035, 3407, 1035, 2126, 1035, 3042, 1005, 1010, 1005, 1056, 1035, 2126, 1035, 3042, 1035, 3504, 1005, 1010, 1005, 1056, 1035, 3042, 1035, 3504, 1035, 2588, 1005, 1010, 1005, 1056, 1035, 3504, 1035, 2588, 1035, 3098, 1005, 1010, 1005, 1056, 1035, 2588, 1035, 3098, 1035, 3065, 1005, 1010, 1005, 1056, 1035, 3098, 1035, 3065, 1035, 6070, 1005, 1010, 1005, 1056, 1035, 3065, 1035, 6070, 1035, 6046, 1005, 1010, 1005, 1056, 1035, 6070, 1035, 6046, 1035, 26462, 1005, 1010, 1005, 1056, 1035, 6046, 1035, 26462, 1035, 2344, 1005, 1010, 1005, 1056, 1035, 26462, 1035, 2344, 1035, 7378, 1005, 1010, 1005, 1056, 1035, 2344, 1035, 7378, 1035, 25416, 3126, 2497, 1005, 1010, 1005, 1056, 1035, 7378, 1035, 25416, 3126, 2497, 1035, 2428, 1005, 1010, 1005, 1056, 1035, 25416, 3126, 2497, 1035, 2428, 1035, 6419, 1005, 1010, 1005, 1056, 1035, 2428, 1035, 6419, 1035, 2047, 1005, 1010, 1005, 1056, 1035, 6419, 1035, 2047, 1035, 6046, 1005, 1010, 1005, 1056, 1035, 2047, 1035, 6046, 1035, 3976, 1005, 1010, 1005, 1056, 1035, 6046, 1035, 3976, 1035, 6450, 1005, 1010, 1005, 1056, 1035, 3976, 1035, 6450, 1035, 2438, 1005, 1010, 1005, 1056, 1035, 6450, 1035, 2438, 1035, 3042, 1005, 1010, 1005, 1056, 1035, 2438, 1035, 3042, 1035, 2147, 1005, 1010, 1005, 1056, 1035, 3042, 1035, 2147, 1035, 2047, 1005, 1010, 1005, 1056, 1035, 2147, 1035, 2047, 1035, 2950, 1005, 1010, 1005, 1056, 1035, 2047, 1035, 2950, 1035, 6046, 1005, 1010, 1005, 1056, 1035, 2950, 1035, 6046, 1035, 2907, 1005, 1010, 1005, 1056, 1035, 6046, 1035, 2907, 1035, 3143, 1005, 1010, 1005, 1056, 1035, 2907, 1035, 3143, 1035, 3715, 1005, 1010, 1005, 1056, 1035, 3143, 1035, 3715, 1035, 7537, 1005, 1033, 1033, 102]\n"]}],"source":["# Example complete:\n","sentence = X_train.values[0]\n","tokens_ = tokenizer.tokenize(sentence)\n","tokens_ = ['[CLS]'] + tokens_ + ['[SEP]']\n","print(\"Tokenized review: \", tokens_)\n","print('Token IDs: ', tokenizer.convert_tokens_to_ids(tokens_))"]},{"cell_type":"markdown","metadata":{"id":"WyvHTAUT0Piq"},"source":["### MAX_LENGTH"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FblrunSFpjDB","executionInfo":{"status":"ok","timestamp":1643217847919,"user_tz":-60,"elapsed":1134,"user":{"displayName":"Mario Bianchi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiYjqJ5A8gRK7lZX57CyeAJHOrmxNdh0QGBaLkAFg=s64","userId":"04504788663289352355"}},"colab":{"base_uri":"https://localhost:8080/","height":264},"outputId":"27d21c7c-a7c4-4523-8730-88dc5994d3ca"},"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"}}],"source":["train = [len(i.split()) for i in X_train]\n","\n","test = [len(i.split()) for i in X_test]\n","\n","for i in [train, test]:\n","  pd.Series(i).hist(bins=20)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nKcHZJHx7lIv"},"outputs":[],"source":["MAX_LENGTH = 25"]},{"cell_type":"markdown","source":["### Aggiungiamo i separatori, convertiamo i token in *integer index*, creiamo le *attention mask*"],"metadata":{"id":"_7d_DgYgz9Do"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"CiAGyh6R3HcQ"},"outputs":[],"source":["def prepare_data(data, max_len):\n","  inputs_ = []\n","  attention_mask = []\n","  for review in data:\n","    encoded_dict = tokenizer.encode_plus(\n","      review, #review to encode = (tokenize + add special character)\n","      add_special_tokens = True, # Add [CLS] for specify classification task and [SEP]\n","      max_length = max_len,\n","      pad_to_max_length  = True, #For pad & truncate all sentence\n","      return_attention_mask = True, # For return attention masks\n","      #return_tensors = 'pt' # Return pythorch tensors\n","    )\n","    # Select encoded sentence    \n","    inputs_.append(encoded_dict['input_ids'])\n","\n","    # Select attention masks\n","    attention_mask.append(encoded_dict['attention_mask'])\n","\n","  # Convert the lists into tensors.\n","  input_ids = torch.tensor(inputs_)\n","  attention_masks = torch.tensor(attention_mask)\n","\n","  return input_ids, attention_masks"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ozTBdDn77JBN","executionInfo":{"status":"ok","timestamp":1643218051803,"user_tz":-60,"elapsed":203889,"user":{"displayName":"Mario Bianchi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiYjqJ5A8gRK7lZX57CyeAJHOrmxNdh0QGBaLkAFg=s64","userId":"04504788663289352355"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"1dde4d04-3211-4c71-83cc-6f21f55678d2"},"outputs":[{"output_type":"stream","name":"stderr","text":["Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2232: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n"]}],"source":["train_data, train_masks = prepare_data(X_train, MAX_LENGTH)\n","test_data, test_masks = prepare_data(X_test, MAX_LENGTH)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qD94OxtI8kkh","executionInfo":{"status":"ok","timestamp":1643218051804,"user_tz":-60,"elapsed":31,"user":{"displayName":"Mario Bianchi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiYjqJ5A8gRK7lZX57CyeAJHOrmxNdh0QGBaLkAFg=s64","userId":"04504788663289352355"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"3c3b80f9-91f5-43e1-fcf5-09b2105a0c40"},"outputs":[{"output_type":"stream","name":"stdout","text":["Original:  ['happy', 'way', 'phone', 'looks', 'upon', 'opening', 'shows', '88', 'battery', 'lifespan', 'order', 'certified', 'refurb', 'really', 'replacing', 'new', 'battery', 'price', 'expensive', 'enough', 'phone', 'work', 'new', 'includes', 'battery', 'hold', 'complete', 'charge', 'pleased', ['B_happy_way', 'B_way_phone', 'B_phone_looks', 'B_looks_upon', 'B_upon_opening', 'B_opening_shows', 'B_shows_88', 'B_88_battery', 'B_battery_lifespan', 'B_lifespan_order', 'B_order_certified', 'B_certified_refurb', 'B_refurb_really', 'B_really_replacing', 'B_replacing_new', 'B_new_battery', 'B_battery_price', 'B_price_expensive', 'B_expensive_enough', 'B_enough_phone', 'B_phone_work', 'B_work_new', 'B_new_includes', 'B_includes_battery', 'B_battery_hold', 'B_hold_complete', 'B_complete_charge', 'B_charge_pleased', 'T_happy_way_phone', 'T_way_phone_looks', 'T_phone_looks_upon', 'T_looks_upon_opening', 'T_upon_opening_shows', 'T_opening_shows_88', 'T_shows_88_battery', 'T_88_battery_lifespan', 'T_battery_lifespan_order', 'T_lifespan_order_certified', 'T_order_certified_refurb', 'T_certified_refurb_really', 'T_refurb_really_replacing', 'T_really_replacing_new', 'T_replacing_new_battery', 'T_new_battery_price', 'T_battery_price_expensive', 'T_price_expensive_enough', 'T_expensive_enough_phone', 'T_enough_phone_work', 'T_phone_work_new', 'T_work_new_includes', 'T_new_includes_battery', 'T_includes_battery_hold', 'T_battery_hold_complete', 'T_hold_complete_charge', 'T_complete_charge_pleased']]\n","Token IDs: tensor([ 101, 1031, 1005, 3407, 1005, 1010, 1005, 2126, 1005, 1010, 1005, 3042,\n","        1005, 1010, 1005, 3504, 1005, 1010, 1005, 2588, 1005, 1010, 1005, 3098,\n","         102])\n","Attention Mask: tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","        1])\n"]}],"source":["# Print sentence 0, now as a list of IDs.\n","print('Original: ', X_train.values[0])\n","print('Token IDs:', train_data[0])\n","print('Attention Mask:', train_masks[0])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IcZFwZapH1Sh"},"outputs":[],"source":["(train_inputs, validation_inputs,\n"," train_labels, validation_labels) = train_test_split(train_data, train_labels,\n","                                                     random_state=42,\n","                                                     test_size=0.1)\n","(train_masks, validation_masks,\n"," _, _) = train_test_split(train_masks, train_data,\n","                          random_state=42, test_size=0.1)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_Xgm_Q9RFgos"},"outputs":[],"source":["# Impostiamo la dimensione dei BATCH\n","\n","BATCH_SIZE = 32"]},{"cell_type":"markdown","source":["### Creiamo i dataloader"],"metadata":{"id":"wL3Uqnv507Hn"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"kEj6_6TsF3ZO"},"outputs":[],"source":["def dataloader(input_ids, attention_masks, labels, name):\n","  dataset = TensorDataset(input_ids, attention_masks, labels) #Combine inputs in to a TensorDataset\n","  if name == \"Train\":\n","    sampler = RandomSampler(dataset)  # Select batches randomly\n","  else:\n","    sampler = SequentialSampler(dataset)  # Select batches sequentially\n","  data_loader = DataLoader(\n","            dataset,\n","            sampler = sampler,\n","            batch_size = BATCH_SIZE # Number of batchsize\n","  )\n","  print(f\"{name} documents {len(dataset)}\")\n","  return data_loader"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"I9sJNGKMG_x2","executionInfo":{"status":"ok","timestamp":1643218051806,"user_tz":-60,"elapsed":12,"user":{"displayName":"Mario Bianchi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiYjqJ5A8gRK7lZX57CyeAJHOrmxNdh0QGBaLkAFg=s64","userId":"04504788663289352355"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"387b2584-490b-4e0a-dccf-d3fc31585106"},"outputs":[{"output_type":"stream","name":"stdout","text":["Train documents 9000\n","Test documents 20000\n","Validation documents 1000\n"]}],"source":["train_dataloader = dataloader(train_inputs, train_masks, train_labels, \"Train\")\n","test_dataloader = dataloader(test_data, test_masks, test_labels, \"Test\")\n","val_dataloader = dataloader(validation_inputs, validation_masks, validation_labels, \"Validation\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0ZyEtnm6VSuT"},"outputs":[],"source":["# Function to calculate the accuracy of our predictions vs labels\n","def accuracy(preds, labels):\n","    pred_flat = np.argmax(preds, axis=1).flatten()\n","    labels_flat = labels.flatten()\n","    return np.sum(pred_flat == labels_flat) / len(labels_flat)"]},{"cell_type":"markdown","metadata":{"id":"EURfgE8lL-su"},"source":["## BERT Initialization"]},{"cell_type":"markdown","metadata":{"id":"E527GymlMHGh"},"source":["Importiamo il modello pre-addestrato *bert-base-uncased*"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NkNa6RvNMCsS"},"outputs":[],"source":["BERTMODEL = \"bert-base-uncased\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wSSp-81yL643","executionInfo":{"status":"ok","timestamp":1643218068023,"user_tz":-60,"elapsed":16225,"user":{"displayName":"Mario Bianchi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiYjqJ5A8gRK7lZX57CyeAJHOrmxNdh0QGBaLkAFg=s64","userId":"04504788663289352355"}},"colab":{"base_uri":"https://localhost:8080/","height":161,"referenced_widgets":["a7e74b3e29474f9fb83d26fa859e174e","76a33d9db69d45968a8a91fbb088814e","a2ec09ad45244ac0bd1f52af0666a948","450b1635696e419f8e44772d2786888c","55f4ec8adcde42eeb6ffd60c5fb3bc10","24066e696dcf4038bbdc7792951e0c4f","f00f7ead3dfe495c8315a23ad41cbd32","1c05f362a10148129df45bfee5e8ff8b","67ff7aaee00946e4b4c76c00837e53c8","a4133cc21a46431bab2b3a9f4226cb82","428d4f853f364bf88131d2666295ed6e"]},"outputId":"7d601a4b-452a-487e-cb17-cce3bf86a7be"},"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a7e74b3e29474f9fb83d26fa859e174e","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/420M [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight']\n","- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}],"source":["model = BertForSequenceClassification.from_pretrained(\n","    BERTMODEL, \n","    num_labels = 2, # Binary classification   \n","    output_attentions = False, \n","    output_hidden_states = False\n",")"]},{"cell_type":"markdown","metadata":{"id":"hRS0T3kZNQ0P"},"source":["To run this model on the GPU"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"n3gULeMNpaFY","executionInfo":{"status":"ok","timestamp":1643218080161,"user_tz":-60,"elapsed":12141,"user":{"displayName":"Mario Bianchi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiYjqJ5A8gRK7lZX57CyeAJHOrmxNdh0QGBaLkAFg=s64","userId":"04504788663289352355"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"b03f00fc-8eb9-4220-bc07-5983cc5aed58"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["BertForSequenceClassification(\n","  (bert): BertModel(\n","    (embeddings): BertEmbeddings(\n","      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n","      (position_embeddings): Embedding(512, 768)\n","      (token_type_embeddings): Embedding(2, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (1): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (2): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (3): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (4): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (5): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (6): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (7): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (8): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (9): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (10): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (11): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): BertPooler(\n","      (dense): Linear(in_features=768, out_features=768, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n","  (dropout): Dropout(p=0.1, inplace=False)\n","  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",")"]},"metadata":{},"execution_count":27}],"source":["model.cuda()"]},{"cell_type":"markdown","metadata":{"id":"yyPv7zDZPDjC"},"source":["Utilizziamo l'ottimizzazione Adam"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lsNN5OG0NRyK"},"outputs":[],"source":["optimizer = AdamW(model.parameters(),\n","                  lr = 2e-5, \n","                  eps = 1e-8\n","                )"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zS0N_idCQEgT"},"outputs":[],"source":["epochs = 2\n","\n","# Total number of training steps is [number of batches] x [number of epochs]. \n","# (Note that this is not the same as the number of training samples).\n","total_steps = len(train_dataloader) * epochs\n","\n","# Create the learning rate scheduler.\n","scheduler = get_linear_schedule_with_warmup(optimizer, \n","                                            num_warmup_steps = 0,\n","                                            num_training_steps = total_steps)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TSSKCkbxTnOY"},"outputs":[],"source":["# Tell PyTorch to use the GPU.    \n","device = torch.device(\"cuda\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"avB8dJweQuSF","executionInfo":{"status":"ok","timestamp":1643218287781,"user_tz":-60,"elapsed":207625,"user":{"displayName":"Mario Bianchi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiYjqJ5A8gRK7lZX57CyeAJHOrmxNdh0QGBaLkAFg=s64","userId":"04504788663289352355"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"54e01859-59cc-452b-84b1-bb2632ccd443"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","======== Epoch 1 / 2 ========\n","Training...\n","\n"," \t Average training loss: 0.47\n","  Accuracy: 0.82\n","  Validation Loss: 0.39\n","\n","======== Epoch 2 / 2 ========\n","Training...\n","\n"," \t Average training loss: 0.36\n","  Accuracy: 0.84\n","  Validation Loss: 0.38\n"]}],"source":["training_stats = []\n","for epoch_i in range(0, epochs):\n","    print(\"\")\n","    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n","    print('Training...')\n","\n","    # Reset the total loss for this epoch.\n","    total_train_loss = 0\n","\n","    model.train()\n","\n","    # For each batch of training data\n","    for step, batch in enumerate(train_dataloader):\n","        b_input_ids = batch[0].to(device) #batch[0] - input_ids\n","        b_input_mask = batch[1].to(device) #batch[1] - attention_masks\n","        b_labels = batch[2].to(device) #batch[2] - labels\n","\n","        # Always clear any previously calculated gradients before performing a\n","        # backward pass. PyTorch doesn't do this automatically because \n","        # accumulating the gradients is \"convenient while training RNNs\".\n","        model.zero_grad() \n","\n","        # Forward pass (for evaluate the model on this training batch)\n","        model1 = model(b_input_ids, \n","                             token_type_ids=None, \n","                             attention_mask=b_input_mask, \n","                             labels=b_labels) \n","        loss = model1.loss\n","        logits = model1.logits\n","        \n","        # Accumulate the training loss over all of the batches so that we can\n","        # calculate the average loss at the end. `loss` is a Tensor containing a\n","        # single value; the `.item()` function just returns the Python value \n","        # from the tensor.\n","        total_train_loss += loss.item()       \n","\n","\n","        # Perform a backward pass to calculate the gradients.\n","        loss.backward()\n","\n","        # Clip the norm of the gradients to 1.0.\n","        # This is to help prevent the \"exploding gradients\" problem.\n","        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n","\n","        # Update parameters and take a step using the computed gradient.\n","        # The optimizer dictates the \"update rule\"--how the parameters are\n","        # modified based on their gradients, the learning rate, etc.\n","        optimizer.step()\n","\n","        # Update the learning rate.\n","        scheduler.step()\n","\n","    # Calculate the average loss over all of the batches.\n","    avg_train_loss = total_train_loss / len(train_dataloader)    \n","\n","    print(\"\\n \\t Average training loss: {0:.2f}\".format(avg_train_loss))\n","    \n","    \n","    # ========================================\n","    #               Validation PHASE \n","    # ========================================\n","    # After the completion of each training epoch, measure our performance on\n","    # our validation set.\n","\n","    # Put the model in evaluation mode--the dropout layers behave differently\n","    # during evaluation.\n","    model.eval()\n","\n","    # Tracking variables \n","    total_eval_accuracy = 0\n","    total_eval_loss = 0\n","    nb_eval_steps = 0\n","\n","    # Evaluate data for one epoch\n","    for batch in val_dataloader:\n","\n","        b_input_ids = batch[0].to(device)\n","        b_input_mask = batch[1].to(device)\n","        b_labels = batch[2].to(device)\n","        \n","        # Tell pytorch not to bother with constructing the compute graph during\n","        # the forward pass, since this is only needed for backprop (training).\n","        with torch.no_grad():        \n","            model2 = model(b_input_ids, \n","                                   token_type_ids=None, \n","                                   attention_mask=b_input_mask,\n","                                   labels=b_labels)\n","            loss = model2.loss\n","            logits = model2.logits\n","        # Accumulate the validation loss.\n","        total_eval_loss += loss.item()\n","\n","        # Move logits and labels to CPU\n","        logits = logits.detach().cpu().numpy()\n","        label_ids = b_labels.to('cpu').numpy()\n","\n","        # Calculate the accuracy for this batch of test sentences, and\n","        # accumulate it over all batches.\n","        total_eval_accuracy += accuracy(logits, label_ids)\n","\n","\n","    # Report the final accuracy for this validation run.\n","    avg_val_accuracy = total_eval_accuracy / len(val_dataloader)\n","    print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n","\n","    # Calculate the average loss over all of the batches.\n","    avg_val_loss = total_eval_loss / len(val_dataloader)\n","    \n","    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n","\n","    # Record all statistics from this epoch.\n","    training_stats.append(\n","        {\n","            'epoch': epoch_i + 1,\n","            'Training Loss': avg_train_loss,\n","            'Valid. Loss': avg_val_loss,\n","            'Valid. Accur.': avg_val_accuracy\n","        }\n","    )"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nKCjAA4nQuVP","executionInfo":{"status":"ok","timestamp":1643218287781,"user_tz":-60,"elapsed":24,"user":{"displayName":"Mario Bianchi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiYjqJ5A8gRK7lZX57CyeAJHOrmxNdh0QGBaLkAFg=s64","userId":"04504788663289352355"}},"colab":{"base_uri":"https://localhost:8080/","height":143},"outputId":"485a8025-9647-474b-f0e9-a7f6b57a3638"},"outputs":[{"output_type":"execute_result","data":{"text/html":["\n","  <div id=\"df-55efd064-9bb6-4d39-be4d-821ae21fba3e\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Training Loss</th>\n","      <th>Valid. Loss</th>\n","      <th>Valid. Accur.</th>\n","    </tr>\n","    <tr>\n","      <th>epoch</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1</th>\n","      <td>0.471191</td>\n","      <td>0.394522</td>\n","      <td>0.822266</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.364553</td>\n","      <td>0.375493</td>\n","      <td>0.841797</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-55efd064-9bb6-4d39-be4d-821ae21fba3e')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-55efd064-9bb6-4d39-be4d-821ae21fba3e button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-55efd064-9bb6-4d39-be4d-821ae21fba3e');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["       Training Loss  Valid. Loss  Valid. Accur.\n","epoch                                           \n","1           0.471191     0.394522       0.822266\n","2           0.364553     0.375493       0.841797"]},"metadata":{},"execution_count":32}],"source":["# Display floats with two decimal places.\n","pd.set_option('precision', 6)\n","\n","# Create a DataFrame from our training statistics.\n","df_stats = pd.DataFrame(data=training_stats)\n","\n","# Use the 'epoch' as the row index.\n","df_stats = df_stats.set_index('epoch')\n","\n","# A hack to force the column headers to wrap.\n","#df = df.style.set_table_styles([dict(selector=\"th\",props=[('max-width', '70px')])])\n","\n","# Display the table.\n","df_stats"]},{"cell_type":"markdown","metadata":{"id":"BqvqMcu6XrX1"},"source":["## Evaluation"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mVNTqe5iQucc"},"outputs":[],"source":["# Put model in evaluation mode\n","model.eval()\n","\n","# Tracking variables \n","predictions , true_labels = [], []\n","\n","# Predict \n","for batch in test_dataloader:\n","  # Add batch to GPU\n","  batch = tuple(t.to(device) for t in batch)\n","  \n","  # Unpack the inputs from our dataloader\n","  b_input_ids, b_input_mask, b_labels = batch\n","  \n","  # Telling the model not to compute or store gradients, saving memory and \n","  # speeding up prediction\n","  with torch.no_grad():\n","      # Forward pass, calculate logit predictions\n","      outputs = model(b_input_ids, token_type_ids=None, \n","                      attention_mask=b_input_mask)\n","\n","  logits = outputs[0]\n","\n","  # Move logits and labels to CPU\n","  logits = logits.detach().cpu().numpy()\n","  label_ids = b_labels.to('cpu').numpy()\n","  prediction = np.argmax(logits, axis=1)\n","\n","  # Store predictions and true labels\n","  for i in prediction:\n","    predictions.append(i)\n","  for i in label_ids:\n","    true_labels.append(i)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8AvSey-PY6E1"},"outputs":[],"source":["def model_evaluation(real_v, pred_v):\n","    print(f\"Accuracy sore: {accuracy_score(real_v, pred_v)}\")\n","    print(\"Classification report:\")\n","    print(classification_report(real_v, pred_v))\n","    cm = confusion_matrix(real_v, pred_v)\n","    print (f\"Confusion matrix \\n {cm}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"z_MDebtnY_DM","executionInfo":{"status":"ok","timestamp":1643218358666,"user_tz":-60,"elapsed":25,"user":{"displayName":"Mario Bianchi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiYjqJ5A8gRK7lZX57CyeAJHOrmxNdh0QGBaLkAFg=s64","userId":"04504788663289352355"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"5b173157-bc44-4f0b-ef23-eb96508e54eb"},"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy sore: 0.7929\n","Classification report:\n","              precision    recall  f1-score   support\n","\n","           0       0.63      0.77      0.69      6075\n","           1       0.89      0.80      0.84     13925\n","\n","    accuracy                           0.79     20000\n","   macro avg       0.76      0.79      0.77     20000\n","weighted avg       0.81      0.79      0.80     20000\n","\n","Confusion matrix \n"," [[ 4664  1411]\n"," [ 2731 11194]]\n"]}],"source":["model_evaluation(true_labels, predictions)"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"5.BERT - Training Set 1.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.3"},"widgets":{"application/vnd.jupyter.widget-state+json":{"a7e74b3e29474f9fb83d26fa859e174e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_76a33d9db69d45968a8a91fbb088814e","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_a2ec09ad45244ac0bd1f52af0666a948","IPY_MODEL_450b1635696e419f8e44772d2786888c","IPY_MODEL_55f4ec8adcde42eeb6ffd60c5fb3bc10"]}},"76a33d9db69d45968a8a91fbb088814e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"a2ec09ad45244ac0bd1f52af0666a948":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_24066e696dcf4038bbdc7792951e0c4f","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"â€‹","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_f00f7ead3dfe495c8315a23ad41cbd32"}},"450b1635696e419f8e44772d2786888c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_1c05f362a10148129df45bfee5e8ff8b","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":440473133,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":440473133,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_67ff7aaee00946e4b4c76c00837e53c8"}},"55f4ec8adcde42eeb6ffd60c5fb3bc10":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_a4133cc21a46431bab2b3a9f4226cb82","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"â€‹","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 420M/420M [00:13&lt;00:00, 33.7MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_428d4f853f364bf88131d2666295ed6e"}},"24066e696dcf4038bbdc7792951e0c4f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"f00f7ead3dfe495c8315a23ad41cbd32":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"1c05f362a10148129df45bfee5e8ff8b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"67ff7aaee00946e4b4c76c00837e53c8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"a4133cc21a46431bab2b3a9f4226cb82":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"428d4f853f364bf88131d2666295ed6e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"nbformat":4,"nbformat_minor":0}